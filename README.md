# Apprentissage-statistique


# üìà Qu'est-ce que la courbe ROC ?

* La courbe ROC (Receiver Operating Characteristic) est un outil graphique utilis√© pour √©valuer la performance d'un mod√®le de classification binaire. Elle trace le taux de vrais positifs (sensibilit√©) en fonction du taux de faux positifs (1 - sp√©cificit√©) √† diff√©rents seuils de classification.

* Chaque point sur la courbe correspond √† une paire (taux de faux positifs, taux de vrais positifs) pour un seuil sp√©cifique. En ajustant ce seuil, on obtient diff√©rents points, formant ainsi la courbe ROC.
  
* On utilise la matrice de confusion pour tracer ces points et bien sur le ROC et l' AUC sont utilis√©s pour des algorithme de classification

![image](https://github.com/user-attachments/assets/ca303b4d-2381-45b4-a67a-8560228b6969)


# üìê Qu'est-ce que l'AUC ?
* L'AUC (Area Under the Curve) repr√©sente l'aire sous la courbe ROC. Elle fournit une mesure unique de la capacit√© du mod√®le √† distinguer entre les classes positives et n√©gatives.
  
* Un AUC  plus √©lev√© indique que le mod√®le a une meilleure capacit√© √† distinguer entre les classes positives et n√©gatives. Cela signifie que, pour un seuil de classification donn√©, le mod√®le est plus susceptible de classer correctement les exemples positifs et n√©gatifs.


# üìä Interpr√©tation de l'AUC
* AUC = 1.0 : Le mod√®le classe parfaitement tous les exemples.

* AUC = 0.5 : Le mod√®le n'a aucune capacit√© discriminante ; ses pr√©dictions sont √©quivalentes √† un tirage al√©atoire.

* AUC < 0.5 : Le mod√®le classe les exemples de mani√®re incorrecte plus souvent que par hasard.

Ainsi, un AUC plus √©lev√© est g√©n√©ralement souhaitable, car il indique une meilleure performance globale du mod√®le.


# ü§î Pourquoi utiliser la courbe ROC et l'AUC ?
* Comparaison de mod√®les : L'AUC permet de comparer objectivement plusieurs mod√®les de classification.

* √âvaluation ind√©pendante du seuil : Contrairement √† d'autres m√©triques comme la pr√©cision ou le rappel, l'AUC √©value la performance du mod√®le sur l'ensemble des seuils possibles.

* Robustesse face au d√©s√©quilibre des classes : La courbe ROC et l'AUC sont particuli√®rement utiles lorsque les classes sont d√©s√©quilibr√©es, car elles ne sont pas influenc√©es par la distribution des classes.

# Exemple
ROC de SVM est meilleure que ROC de logistic (comparaison avec l'AUC)
![image](https://github.com/user-attachments/assets/0f39de65-df4f-4e0b-b486-58370a69e393)



# üéØ Comment savoir si le Gini est utile ?
* L‚Äôindice de Gini mesure l‚Äôimpuret√© :

* Plus il est petit, plus les classes sont pures (bien s√©par√©es).

* Ce qui compte, c‚Äôest la baisse de l‚Äôindice de Gini apr√®s la s√©paration.

# ‚úÖ S√©paration utile selon Gini si :
* Gini¬†apr√®s split < Gini¬†avant¬†split
* ‚û°Ô∏è Il n‚Äôy a pas de valeur seuil fixe.
* ‚û°Ô∏è M√™me une petite diminution signifie une am√©lioration, donc la s√©paration est b√©n√©fique.


# ‚ö†Ô∏è Pourquoi le taux d‚Äôerreur peut √™tre trompeur ?
Le taux d‚Äôerreur regarde seulement la proportion d‚Äôerreurs (√©l√©ments mal class√©s selon la classe majoritaire). Il ne tient pas compte du niveau de m√©lange entre les classes.

# ‚ùå Exemple typique :
Deux groupes : l‚Äôun tr√®s pur, l‚Äôautre tr√®s m√©lang√©

Le taux d‚Äôerreur peut rester identique avant/apr√®s

Mais Gini, lui, capte la baisse de m√©lange









