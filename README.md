# Apprentissage-statistique


# üìà Qu'est-ce que la courbe ROC ?

* La courbe ROC (Receiver Operating Characteristic) est un outil graphique utilis√© pour √©valuer la performance d'un mod√®le de classification binaire. Elle trace le taux de vrais positifs (sensibilit√©) en fonction du taux de faux positifs (1 - sp√©cificit√©) √† diff√©rents seuils de classification.

* Chaque point sur la courbe correspond √† une paire (taux de faux positifs, taux de vrais positifs) pour un seuil sp√©cifique. En ajustant ce seuil, on obtient diff√©rents points, formant ainsi la courbe ROC.
  
* On utilise la matrice de confusion pour tracer ces points et bien sur le ROC et l' AUC sont utilis√©s pour des algorithme de classification

![image](https://github.com/user-attachments/assets/ca303b4d-2381-45b4-a67a-8560228b6969)


# üìê Qu'est-ce que l'AUC ?
* L'AUC (Area Under the Curve) repr√©sente l'aire sous la courbe ROC. Elle fournit une mesure unique de la capacit√© du mod√®le √† distinguer entre les classes positives et n√©gatives.
  
* Un AUC  plus √©lev√© indique que le mod√®le a une meilleure capacit√© √† distinguer entre les classes positives et n√©gatives. Cela signifie que, pour un seuil de classification donn√©, le mod√®le est plus susceptible de classer correctement les exemples positifs et n√©gatifs.


# üìä Interpr√©tation de l'AUC
* AUC = 1.0 : Le mod√®le classe parfaitement tous les exemples.

* AUC = 0.5 : Le mod√®le n'a aucune capacit√© discriminante ; ses pr√©dictions sont √©quivalentes √† un tirage al√©atoire.

* AUC < 0.5 : Le mod√®le classe les exemples de mani√®re incorrecte plus souvent que par hasard.

Ainsi, un AUC plus √©lev√© est g√©n√©ralement souhaitable, car il indique une meilleure performance globale du mod√®le.


# ü§î Pourquoi utiliser la courbe ROC et l'AUC ?
* Comparaison de mod√®les : L'AUC permet de comparer objectivement plusieurs mod√®les de classification.

* √âvaluation ind√©pendante du seuil : Contrairement √† d'autres m√©triques comme la pr√©cision ou le rappel, l'AUC √©value la performance du mod√®le sur l'ensemble des seuils possibles.

* Robustesse face au d√©s√©quilibre des classes : La courbe ROC et l'AUC sont particuli√®rement utiles lorsque les classes sont d√©s√©quilibr√©es, car elles ne sont pas influenc√©es par la distribution des classes.

# Exemple
ROC de SVM est meilleure que ROC de logistic (comparaison avec l'AUC)
![image](https://github.com/user-attachments/assets/0f39de65-df4f-4e0b-b486-58370a69e393)


# üß† Crit√®res de s√©paration en arbre de d√©cision
## ‚úÖ 1. Indice de Gini
Formule : ![image](https://github.com/user-attachments/assets/0ac6519e-5b84-468d-8f95-2e874b57e335)

Valeurs :

- Gini = 0 : ensemble pur (une seule classe)

- Gini ‚âà 1 : classes tr√®s m√©lang√©es

## ‚ùå 2. Taux d'erreur
Formule :
![image](https://github.com/user-attachments/assets/4109c632-c32e-40f9-8e25-7c9283978b2f)

- Taux d‚Äôerreur est la proportion de la classe majoritaire.

- Limite : ne d√©tecte pas les m√©langes subtils entre classes.

- S√©paration utile si :
Erreur_apres_split < Erreur_avant_split

## üî• 3. Entropie (Shannon)
- Formule :
![image](https://github.com/user-attachments/assets/209f4fa2-ddbf-4b96-82e9-0e59e5ca0dc9)
- Valeurs :

Entropie = 0 : ensemble pur

Entropie max = log‚ÇÇ(C) si les classes sont √©quilibr√©es

S√©paration utile si :
Entropie¬†apres¬†split<Entropie¬†avant¬†split
## üìà 4. Gain d'information
Formule :
Gain=Impurete avant¬†split‚àíImpurete¬†apres¬†split


Peut √™tre appliqu√© avec :
- Gini ‚Üí Gain de Gini
- Entropie ‚Üí Information Gain

‚û°Ô∏è Plus le **gain est √©lev√©**, meilleure est la s√©paration.

---

## ‚úÖ R√®gles g√©n√©rales √† retenir

| Crit√®re        | Formule                        | Bonne s√©paration ?         |
|----------------|--------------------------------|----------------------------|
| Gini           | `1 - ‚àë p·µ¢¬≤`                     | Gini_apr√®s < Gini_avant    |
| Entropie       | `- ‚àë p·µ¢ * log‚ÇÇ(p·µ¢)`             | Entropie_apr√®s < Entropie_avant |
| Taux d‚Äôerreur  | `1 - max(p·µ¢)`                   | Erreur_apr√®s < Erreur_avant|
| Gain           | `Impuret√©_avant - Impuret√©_apr√®s` | Plus il est √©lev√©, mieux c'est |

---

# üéØ √Ä retenir sur Gini et taux d‚Äôerreur

## ‚úÖ Gini
- Mesure l‚Äôimpuret√©.
- Plus il est **faible**, plus le n≈ìud est **pur**.
- Une **petite baisse** de Gini = **split b√©n√©fique**.

## ‚ùå Taux d‚Äôerreur
- Ignore les m√©langes subtils.
- Peut √™tre **trompeur** : un n≈ìud tr√®s m√©lang√© peut avoir le m√™me taux d‚Äôerreur qu‚Äôun n≈ìud presque pur.

---

## üìù Exemple typique
- Groupe 1 : 100% classe A ‚Üí erreur = 0
- Groupe 2 : 51% classe A, 49% classe B ‚Üí erreur = 0.49  
‚Üí Le taux d‚Äôerreur ne capte **pas** le niveau de m√©lange, mais **Gini, oui**.

---



# üéØ Comment savoir si le Gini est utile ?
* L‚Äôindice de Gini mesure l‚Äôimpuret√© :

* Plus il est petit, plus les classes sont pures (bien s√©par√©es).

* Ce qui compte, c‚Äôest la baisse de l‚Äôindice de Gini apr√®s la s√©paration.

# ‚úÖ S√©paration utile selon Gini si :
* Gini¬†apr√®s split < Gini¬†avant¬†split
* ‚û°Ô∏è Il n‚Äôy a pas de valeur seuil fixe.
* ‚û°Ô∏è M√™me une petite diminution signifie une am√©lioration, donc la s√©paration est b√©n√©fique.


# ‚ö†Ô∏è Pourquoi le taux d‚Äôerreur peut √™tre trompeur ?
* Le taux d‚Äôerreur regarde seulement la proportion d‚Äôerreurs (√©l√©ments mal class√©s selon la classe majoritaire). Il ne tient pas compte du niveau de m√©lange entre les classes.

# ‚ùå Exemple typique :
* Deux groupes : l‚Äôun tr√®s pur, l‚Äôautre tr√®s m√©lang√©

* Le taux d‚Äôerreur peut rester identique avant/apr√®s

* Mais Gini, lui, capte la baisse de m√©lange










